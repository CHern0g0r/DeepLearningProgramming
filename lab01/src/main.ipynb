{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "import numpy_utils.layers\n",
    "\n",
    "from importlib import reload\n",
    "from scipy.io import loadmat\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torch.nn import (\n",
    "    AdaptiveAvgPool2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    SiLU,\n",
    "    Sigmoid,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNorm2d,\n",
    "    Sequential,\n",
    "    AvgPool2d\n",
    ")\n",
    "\n",
    "from numpy_utils.layers import (\n",
    "    Layer,\n",
    "    LinearLayer,\n",
    "    ConvLayer,\n",
    "    SiLULayer,\n",
    "    SigmoidLayer,\n",
    "    CrossEntropyLoss,\n",
    "    CrossEntropyCost,\n",
    "    SoftmaxLayer,\n",
    "    FlattenLayer,\n",
    "    OneLayer,\n",
    "    DropoutLayer,\n",
    "    BatchNorm2dLayer,\n",
    "    DepthwiseConvLayer,\n",
    "    AdaptiveAvgPool2dLayer,\n",
    "    AvgPool2dLayer\n",
    ")\n",
    "from data_utils.dataset import CarsDataset\n",
    "from numpy_utils.utils import check_comb, ttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# plt.rcParams['figure.figsize'] = (15, 5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_mat_to_csv(mat_path, csv_path):\n",
    "    meta = loadmat(mat_path)\n",
    "    annots = meta['annotations']\n",
    "    c_name = annots[:, :][['class', 'fname']].squeeze(0)\n",
    "    c = list(map(lambda x: x.item(), c_name['class']))\n",
    "    name = list(map(lambda x: x.item(), c_name['fname']))\n",
    "    df = pd.DataFrame({\n",
    "        'class': c,\n",
    "        'fname': name\n",
    "    })\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_mat_to_csv('../data/cars_train_annos.mat', '../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = CarsDataset('../data/train', '../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8144,) (8144,)\n"
     ]
    }
   ],
   "source": [
    "it = iter(dts)\n",
    "hws = np.array((list(map(lambda x: x[0].size, it))))\n",
    "h, w = map(lambda x: x.squeeze(1), np.split(hws, 2, axis=1))\n",
    "print(h.shape, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(h)))\n",
    "print(len(np.unique(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(X, ft, fn, ac=True):\n",
    "    out = ft(X).detach().numpy()\n",
    "    outn = fn(X.detach().numpy())\n",
    "    print('MSE', np.power(out - outn, 2).sum())\n",
    "    if ac:\n",
    "        print('eq', np.allclose(out, outn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b0(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = Linear(512, 128)\n",
    "ln = LinearLayer(512, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.W = lt.weight.data.numpy()\n",
    "ln.b = lt.bias.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1, 512))\n",
    "Xn = X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5755734e-13\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "out = lt(X).detach().numpy()\n",
    "outn = ln(Xn)\n",
    "print(np.power(out - outn, 2).sum())\n",
    "print(np.allclose(out, outn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = Conv2d(3, 4, 3)\n",
    "cn = ConvLayer(3, 4, 3)\n",
    "wt, bt = ct._parameters.values()\n",
    "# cn.W = np.transpose(wt.data.numpy(), (0, 1, 2, 3))\n",
    "cn.W = wt.data.numpy()\n",
    "cn.b = bt.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(4, 3, 5, 5)\n",
    "Xn = X.numpy()\n",
    "# Xn = np.arange(48).reshape(1, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 3, 3) (4, 4, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "out = ct(X).detach().numpy()\n",
    "outn = cn(Xn)\n",
    "print(*(x.shape for x in (out, outn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0724481e-13\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.power(out - outn, 2).sum())\n",
    "# print(np.power(out - outn2, 2).sum())\n",
    "# print(np.power(out - outn3, 2).sum())\n",
    "# print(np.power(out - outn4, 2).sum())\n",
    "print(np.allclose(out, outn))\n",
    "# print(np.allclose(out, outn2))\n",
    "# print(np.allclose(out, outn3))\n",
    "# print(np.allclose(out, outn4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1.339315e-13\n",
      "eq True\n",
      "MSE 1.314504e-13\n",
      "eq True\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(5, 3, 4, 4)\n",
    "compare(X, SiLU(), SiLULayer())\n",
    "compare(X, Sigmoid(), SigmoidLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(5, 3, 16, 16)\n",
    "avgpool = AdaptiveAvgPool2d(output_size=1)\n",
    "out = avgpool(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Md(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(8, 4)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.l1(X)\n",
    "        x = self.act1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md = Md()\n",
    "md = nn.Linear(8, 4)\n",
    "mdn = LinearLayer(8, 4)\n",
    "mdn.W = md.weight.data.numpy()\n",
    "mdn.b = md.bias.data.numpy()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(5, 8)\n",
    "lab = torch.randint(0, 4, (5,))\n",
    "Xn = X.numpy()\n",
    "labn = lab.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3982, grad_fn=<NllLossBackward0>)\n",
      "1.3982131\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "out = md(X)\n",
    "outn = mdn(Xn)\n",
    "loss = crit(out, lab)\n",
    "lossn = critn(outn, labn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()\n",
    "sm = SoftmaxLayer()\n",
    "cre = CrossEntropyCost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = torch.rand(10, 4, requires_grad=True)\n",
    "lab0 = torch.randint(0, 4, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "# X = torch.rand(bs, 4, requires_grad=True)\n",
    "# lab = torch.randint(0, 4, (bs,))\n",
    "X = X0[:bs, :].clone().detach().requires_grad_(True)\n",
    "lab = lab0[:bs].clone().detach()\n",
    "Xn = X.detach().numpy()\n",
    "labn = lab.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "out1 = crit(X, lab)\n",
    "out2 = critn(Xn, labn)\n",
    "_out3 = sm(Xn)\n",
    "out3 = cre(_out3, labn)\n",
    "print(np.allclose(out1.detach(), out3))\n",
    "print(np.allclose(out1.detach(), out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward is right True\n"
     ]
    }
   ],
   "source": [
    "rest, resn, xts, xns, gt, gn = check_comb([crit], [sm, cre], X0, lab0, return_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = nn.Linear(4, 4)\n",
    "mdn = LinearLayer(10, 4)\n",
    "mdn.W = md.weight.data.numpy()\n",
    "mdn.b = md.bias.data.numpy()\n",
    "sil = SiLU()\n",
    "siln = SiLULayer()\n",
    "sig = Sigmoid()\n",
    "sign = SigmoidLayer()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()\n",
    "c = Conv2d(3, 4, 3)\n",
    "cn = ConvLayer(3, 4, 3)\n",
    "cn.W = c.weight.data.numpy()\n",
    "cn.b = c.bias.data.numpy()\n",
    "dc = Conv2d(2, 2, 3, stride=(2,2), groups=2, bias=False)\n",
    "dcn = DepthwiseConvLayer(2, 3, stride=2)\n",
    "dcn.W = ttn(dc.weight.data)\n",
    "f = Flatten()\n",
    "fn = FlattenLayer()\n",
    "trash = OneLayer()\n",
    "d = Dropout()\n",
    "dn = DropoutLayer()\n",
    "b = BatchNorm2d(4, track_running_stats=False)\n",
    "bn = BatchNorm2dLayer(4)\n",
    "bn.W = ttn(b.weight.data)\n",
    "bn.b = ttn(b.bias.data)\n",
    "a = AvgPool2d(2)\n",
    "ad = AdaptiveAvgPool2d(1)\n",
    "an = AvgPool2dLayer(2)\n",
    "adn = AdaptiveAvgPool2dLayer(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "X0 = torch.rand(bs, 3, 5, 5, requires_grad=True)\n",
    "# X0 = torch.rand(bs, 4, 3, 3, requires_grad=True)\n",
    "lab0 = torch.randint(0, 4, (bs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1813/1255000145.py\", line 4, in <cell line: 3>\n",
      "    res = check_comb([c, a, f, md], [c, ad, f, md], X0) #, lab0, return_grad=True)\n",
      "  File \"/home/chern0g0r/labs/DeepLearningProgramming/lab01/src/numpy_utils/utils.py\", line 58, in check_comb\n",
      "    show('Forward is right', np.allclose(ttn(rest), resn))\n",
      "  File \"<__array_function__ internals>\", line 180, in allclose\n",
      "  File \"/home/chern0g0r/envs/jupyter_env/lib/python3.9/site-packages/numpy/core/numeric.py\", line 2251, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 180, in isclose\n",
      "  File \"/home/chern0g0r/envs/jupyter_env/lib/python3.9/site-packages/numpy/core/numeric.py\", line 2345, in isclose\n",
      "    y = asanyarray(b)\n",
      "  File \"/home/chern0g0r/envs/jupyter_env/lib/python3.9/site-packages/torch/_tensor.py\", line 678, in __array__\n",
      "    return self.numpy()\n",
      "RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n"
     ]
    }
   ],
   "source": [
    "# [cn, bn, fn, mdn, critn]\n",
    "# [dcn, fn, mdn, critn]\n",
    "try:\n",
    "    res = check_comb([c, a, f, md], [c, ad, f, md], X0) #, lab0, return_grad=True)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 5, 5) (10, 4, 3, 3) (10, 4, 1, 1) (10, 4) (10, 4)\n"
     ]
    }
   ],
   "source": [
    "_, _, xts, *_ = res\n",
    "print(*(tuple(t.shape) for t in xts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "rest, resn, xts, xns, gt, gn = res\n",
    "print(len(gt), len(gn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 4\n",
    "print('\\n'.join(map(lambda x: str(np.allclose(x[0], x[1])), zip(gt, gn, list(range(grad_idx))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4) (10, 18) (10, 2, 3, 3) (10, 2, 5, 5)\n",
      "(10, 4) (10, 18) (10, 2, 3, 3) (10, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(*(tuple(t.shape) for t in gt))\n",
    "print(*(t.shape for t in gn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0067, -0.0067, -0.0005],\n",
      "        [ 0.0169,  0.0013, -0.0055],\n",
      "        [-0.0087,  0.0018, -0.0056]])\n",
      "[[-0.00669819 -0.00673318 -0.00050039]\n",
      " [ 0.01692147  0.00127935 -0.00553685]\n",
      " [-0.00866423  0.00183728 -0.00556004]]\n"
     ]
    }
   ],
   "source": [
    "print(gt[-2][0, 0])\n",
    "print(gn[-2][0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Conv2d(2, 2, 3, groups=2, bias=False)\n",
    "# dc = Conv2d(1, 1, 3, bias=False)\n",
    "# c = ConvLayer(1, 1, 3, bias=False)\n",
    "dcl = DepthwiseConvLayer(2, 3)\n",
    "dcl.W = ttn(dc.weight.data)\n",
    "# c.W = ttn(dc.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "x = torch.rand(bs, 2, 5, 5)\n",
    "xn = ttn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3, 3])\n",
      "(4, 2, 3, 3)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t = dc(x)\n",
    "# k = c(xn)\n",
    "n = dcl(xn)\n",
    "print(t.shape)\n",
    "# print(k.shape)\n",
    "print(n.shape)\n",
    "# print(np.allclose(ttn(t), k))\n",
    "print(np.allclose(ttn(t), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0164, -0.1271, -0.2785],\n",
      "        [ 0.2601,  0.3826,  0.1922],\n",
      "        [-0.3220,  0.0859,  0.3928]], grad_fn=<SelectBackward0>)\n",
      "[[ 0.01635781 -0.12706697 -0.27846497]\n",
      " [ 0.26005393  0.38260096  0.19220147]\n",
      " [-0.32200667  0.08593589  0.39278188]]\n"
     ]
    }
   ],
   "source": [
    "print(t[0, 0])\n",
    "print(k[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jupyter_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11e7b04fea54ca48423a4346d276b2eeee041e75d91fae35da36614c12a42435"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
