{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "import numpy_utils.layers\n",
    "\n",
    "from importlib import reload\n",
    "from scipy.io import loadmat\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torch.nn import (\n",
    "    AdaptiveAvgPool2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    SiLU,\n",
    "    Sigmoid,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNorm2d,\n",
    "    Sequential,\n",
    "    AvgPool2d\n",
    ")\n",
    "\n",
    "from numpy_utils.layers import (\n",
    "    Layer,\n",
    "    LinearLayer,\n",
    "    ConvLayer,\n",
    "    SiLULayer,\n",
    "    SigmoidLayer,\n",
    "    CrossEntropyLoss,\n",
    "    CrossEntropyCost,\n",
    "    SoftmaxLayer,\n",
    "    FlattenLayer,\n",
    "    OneLayer,\n",
    "    DropoutLayer,\n",
    "    BatchNorm2dLayer,\n",
    "    DepthwiseConvLayer,\n",
    "    AdaptiveAvgPool2dLayer,\n",
    "    AvgPool2dLayer,\n",
    "    SequentialLayer,\n",
    "    SqueezeExcitationLayer\n",
    ")\n",
    "from torch_utils.layers import (\n",
    "    MBconfig,\n",
    "    StochDepth\n",
    ")\n",
    "from torch_utils.models import EfficientNet\n",
    "from data_utils.dataset import CarsDataset\n",
    "from numpy_utils.utils import check_comb, ttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = (15, 5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_mat_to_csv(mat_path, csv_path):\n",
    "    meta = loadmat(mat_path)\n",
    "    annots = meta['annotations']\n",
    "    c_name = annots[:, :][['class', 'fname']].squeeze(0)\n",
    "    c = list(map(lambda x: x.item(), c_name['class']))\n",
    "    name = list(map(lambda x: x.item(), c_name['fname']))\n",
    "    df = pd.DataFrame({\n",
    "        'class': c,\n",
    "        'fname': name\n",
    "    })\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_mat_to_csv('../data/cars_train_annos.mat', '../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = CarsDataset('../data/train', '../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"00266.jpg\",\n",
      "\"01085.jpg\",\n",
      "\"02176.jpg\",\n",
      "\"03048.jpg\",\n",
      "\"03439.jpg\",\n",
      "\"03469.jpg\",\n",
      "\"03539.jpg\",\n",
      "\"04577.jpg\",\n",
      "\"04848.jpg\",\n",
      "\"05177.jpg\",\n",
      "\"05502.jpg\",\n",
      "\"05713.jpg\",\n",
      "\"06947.jpg\",\n",
      "\"07383.jpg\",\n",
      "\"07693.jpg\",\n",
      "\"07774.jpg\",\n",
      "\"08137.jpg\",\n",
      "\"08144.jpg\",\n"
     ]
    }
   ],
   "source": [
    "numc = []\n",
    "for i in range(len(dts)):\n",
    "    img, target = dts[i]\n",
    "    numc.append(len(img.mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onec = {\n",
    "    \"00266.jpg\",\n",
    "    \"01085.jpg\",\n",
    "    \"02176.jpg\",\n",
    "    \"03048.jpg\",\n",
    "    \"03439.jpg\",\n",
    "    \"03469.jpg\",\n",
    "    \"03539.jpg\",\n",
    "    \"04577.jpg\",\n",
    "    \"04848.jpg\",\n",
    "    \"05177.jpg\",\n",
    "    \"05502.jpg\",\n",
    "    \"05713.jpg\",\n",
    "    \"06947.jpg\",\n",
    "    \"07383.jpg\",\n",
    "    \"07693.jpg\",\n",
    "    \"07774.jpg\",\n",
    "    \"08137.jpg\",\n",
    "    \"08144.jpg\",\n",
    "}\n",
    "ann_path = '../data/train.csv'\n",
    "new_ann_path = '../data/train1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(ann_path)\n",
    "new_df = df[~df['fname'].isin(onec)]\n",
    "print(len(df) - len(new_df))\n",
    "new_df.to_csv(new_ann_path, index=False)\n",
    "# print(len(pd.read_csv(new_ann_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(min(np.unique(new_df['class'])))\n",
    "# new_df['class'] -= 1\n",
    "print(min(np.unique(new_df['class'])))\n",
    "new_df.to_csv(new_ann_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 3]), array([  18, 8126]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(numc, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8144,) (8144,)\n"
     ]
    }
   ],
   "source": [
    "it = iter(dts)\n",
    "hws = np.array((list(map(lambda x: x[0].size, it))))\n",
    "h, w = map(lambda x: x.squeeze(1), np.split(hws, 2, axis=1))\n",
    "print(h.shape, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(h)))\n",
    "print(len(np.unique(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(X, ft, fn, ac=True):\n",
    "    out = ft(X).detach().numpy()\n",
    "    outn = fn(X.detach().numpy())\n",
    "    print('MSE', np.power(out - outn, 2).sum())\n",
    "    if ac:\n",
    "        print('eq', np.allclose(out, outn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b0(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = Linear(512, 128)\n",
    "ln = LinearLayer(512, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.W = lt.weight.data.numpy()\n",
    "ln.b = lt.bias.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1, 512))\n",
    "Xn = X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5755734e-13\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "out = lt(X).detach().numpy()\n",
    "outn = ln(Xn)\n",
    "print(np.power(out - outn, 2).sum())\n",
    "print(np.allclose(out, outn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = Conv2d(3, 4, 3)\n",
    "cn = ConvLayer(3, 4, 3)\n",
    "wt, bt = ct._parameters.values()\n",
    "# cn.W = np.transpose(wt.data.numpy(), (0, 1, 2, 3))\n",
    "cn.W = wt.data.numpy()\n",
    "cn.b = bt.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(4, 3, 5, 5)\n",
    "Xn = X.numpy()\n",
    "# Xn = np.arange(48).reshape(1, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 3, 3) (4, 4, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "out = ct(X).detach().numpy()\n",
    "outn = cn(Xn)\n",
    "print(*(x.shape for x in (out, outn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0724481e-13\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.power(out - outn, 2).sum())\n",
    "# print(np.power(out - outn2, 2).sum())\n",
    "# print(np.power(out - outn3, 2).sum())\n",
    "# print(np.power(out - outn4, 2).sum())\n",
    "print(np.allclose(out, outn))\n",
    "# print(np.allclose(out, outn2))\n",
    "# print(np.allclose(out, outn3))\n",
    "# print(np.allclose(out, outn4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1.339315e-13\n",
      "eq True\n",
      "MSE 1.314504e-13\n",
      "eq True\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(5, 3, 4, 4)\n",
    "compare(X, SiLU(), SiLULayer())\n",
    "compare(X, Sigmoid(), SigmoidLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(5, 3, 16, 16)\n",
    "avgpool = AdaptiveAvgPool2d(output_size=1)\n",
    "out = avgpool(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Md(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(8, 4)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.l1(X)\n",
    "        x = self.act1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md = Md()\n",
    "md = nn.Linear(8, 4)\n",
    "mdn = LinearLayer(8, 4)\n",
    "mdn.W = md.weight.data.numpy()\n",
    "mdn.b = md.bias.data.numpy()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(5, 8)\n",
    "lab = torch.randint(0, 4, (5,))\n",
    "Xn = X.numpy()\n",
    "labn = lab.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3982, grad_fn=<NllLossBackward0>)\n",
      "1.3982131\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "out = md(X)\n",
    "outn = mdn(Xn)\n",
    "loss = crit(out, lab)\n",
    "lossn = critn(outn, labn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()\n",
    "sm = SoftmaxLayer()\n",
    "cre = CrossEntropyCost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = torch.rand(10, 4, requires_grad=True)\n",
    "lab0 = torch.randint(0, 4, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "# X = torch.rand(bs, 4, requires_grad=True)\n",
    "# lab = torch.randint(0, 4, (bs,))\n",
    "X = X0[:bs, :].clone().detach().requires_grad_(True)\n",
    "lab = lab0[:bs].clone().detach()\n",
    "Xn = X.detach().numpy()\n",
    "labn = lab.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "out1 = crit(X, lab)\n",
    "out2 = critn(Xn, labn)\n",
    "_out3 = sm(Xn)\n",
    "out3 = cre(_out3, labn)\n",
    "print(np.allclose(out1.detach(), out3))\n",
    "print(np.allclose(out1.detach(), out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward is right True\n"
     ]
    }
   ],
   "source": [
    "rest, resn, xts, xns, gt, gn = check_comb([crit], [sm, cre], X0, lab0, return_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = nn.Linear(676, 4)\n",
    "mdn = LinearLayer(676, 4)\n",
    "mdn.W = md.weight.data.numpy()\n",
    "mdn.b = md.bias.data.numpy()\n",
    "sil = SiLU()\n",
    "siln = SiLULayer()\n",
    "sig = Sigmoid()\n",
    "sign = SigmoidLayer()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()\n",
    "c = Conv2d(3, 4, 3)\n",
    "cn = ConvLayer(3, 4, 3)\n",
    "cn.W = c.weight.data.numpy()\n",
    "cn.b = c.bias.data.numpy()\n",
    "dc = Conv2d(2, 2, 3, stride=(2,2), groups=2, bias=False)\n",
    "dcn = DepthwiseConvLayer(2, 3, stride=2)\n",
    "dcn.W = ttn(dc.weight.data)\n",
    "f = Flatten()\n",
    "fn = FlattenLayer()\n",
    "trash = OneLayer()\n",
    "d = Dropout()\n",
    "dn = DropoutLayer()\n",
    "b = BatchNorm2d(4, track_running_stats=False)\n",
    "bn = BatchNorm2dLayer(4)\n",
    "bn.W = ttn(b.weight.data)\n",
    "bn.b = ttn(b.bias.data)\n",
    "a = AvgPool2d(2)\n",
    "ad = AdaptiveAvgPool2d(6)\n",
    "an = AvgPool2dLayer(2)\n",
    "adn = AdaptiveAvgPool2dLayer(6)\n",
    "seq = Sequential(c, b, f, md)\n",
    "seqn = SequentialLayer(cn, bn, fn, mdn)\n",
    "seq1 = SequentialLayer(seqn, seqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "X0 = torch.rand(bs, 3, 15, 15, requires_grad=True)\n",
    "# X0 = torch.rand(bs, 4, requires_grad=True)\n",
    "lab0 = torch.randint(0, 4, (bs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward is right True\n",
      "but 1.4210854715202004e-14\n"
     ]
    }
   ],
   "source": [
    "# [cn, bn, fn, mdn, critn]\n",
    "# [dcn, fn, mdn, critn]\n",
    "try:\n",
    "    res = check_comb([seq, crit], [seqn, critn], X0, lab0, return_grad=True)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "rest, resn, xts, xns, gt, gn = res\n",
    "print(len(gt), len(gn))\n",
    "print(len(xts), len(xns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 5\n",
    "print('\\n'.join(map(lambda x: str(np.allclose(x[0], x[1])), zip(gt, gn, list(range(grad_idx))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 6\n",
    "print('\\n'.join(map(lambda x: str(np.allclose(ttn(x[0]), x[1])), zip(xts, xns, list(range(grad_idx))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X deltas:\n",
      "0.0\n",
      "5.163924681822105e-16\n",
      "1.4210854715202004e-14\n",
      "------------------------------\n",
      "dX deltas:\n",
      "1.1397676087886308e-19\n",
      "6.24932017377787e-22\n",
      "------------------------------\n",
      "dXn mean\n",
      "1.8626452e-10\n",
      "-4.4151588e-12\n",
      "------------------------------\n",
      "dXt mean\n",
      "8.381903e-10\n",
      "-3.090611e-11\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 6\n",
    "print('X deltas:')\n",
    "print('\\n'.join(map(lambda x: str(np.mean(ttn(x[0]) - x[1])**2), zip(xts, xns, list(range(grad_idx))))))\n",
    "print('-'*30)\n",
    "print('dX deltas:')\n",
    "print('\\n'.join(map(lambda x: str(np.mean(ttn(x[0]) - x[1])**2), zip(gt, gn, list(range(grad_idx-1))))))\n",
    "print('-'*30)\n",
    "print('dXn mean')\n",
    "print('\\n'.join(map(str, map(np.mean, gn))))\n",
    "print('-'*30)\n",
    "print('dXt mean')\n",
    "print('\\n'.join(map(str, map(np.mean, map(ttn, gt)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 15, 15) (10, 4) ()\n",
      "(10, 3, 15, 15) (10, 4) ()\n",
      "(10, 4) (10, 3, 15, 15)\n",
      "(10, 4) (10, 3, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "print(*map(lambda x: tuple(x.shape), xts))\n",
    "print(*map(lambda x: x.shape, xns))\n",
    "print(*map(lambda x: tuple(x.shape), gt))\n",
    "print(*map(lambda x: x.shape, gn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "se = SqueezeExcitationLayer(32, 8)\n",
    "X = np.random.rand(1, 32, 8, 8)\n",
    "r = se(X)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = StochDepth(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(8, 32, 256, 256)\n",
    "y = sd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 256, 256])\n",
      "8388608 / 16777216: 0.5\n",
      "tensor([2097584.2500,       0.0000,       0.0000, 2097113.5000, 2098659.0000,\n",
      "        2098461.2500,       0.0000,       0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "nz = y.count_nonzero()\n",
    "tot = np.prod(y.shape)\n",
    "print(f'{nz} / {tot}: {nz / tot}')\n",
    "lsum = y.sum(axis=(1, 2, 3))\n",
    "print(lsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63de50e7b25e2d4530c1fba2f289d719b4cf6796b377066a37d3e20c0a10034f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
