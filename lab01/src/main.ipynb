{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "import numpy_utils.layers\n",
    "\n",
    "from importlib import reload\n",
    "from scipy.io import loadmat\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torch.nn import (\n",
    "    AdaptiveAvgPool2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    SiLU,\n",
    "    Sigmoid,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNorm2d,\n",
    "    Sequential,\n",
    "    AvgPool2d\n",
    ")\n",
    "\n",
    "from numpy_utils.layers import (\n",
    "    Layer,\n",
    "    LinearLayer,\n",
    "    ConvLayer,\n",
    "    SiLULayer,\n",
    "    SigmoidLayer,\n",
    "    CrossEntropyLoss,\n",
    "    CrossEntropyCost,\n",
    "    SoftmaxLayer,\n",
    "    FlattenLayer,\n",
    "    OneLayer,\n",
    "    DropoutLayer,\n",
    "    BatchNorm2dLayer,\n",
    "    DepthwiseConvLayer,\n",
    "    AdaptiveAvgPool2dLayer,\n",
    "    AvgPool2dLayer,\n",
    "    SequentialLayer,\n",
    "    SqueezeExcitationLayer\n",
    ")\n",
    "from torch_utils.layers import (\n",
    "    MBconfig\n",
    ")\n",
    "from torch_utils.models import EfficientNet\n",
    "from data_utils.dataset import CarsDataset\n",
    "from numpy_utils.utils import check_comb, ttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = (15, 5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_mat_to_csv(mat_path, csv_path):\n",
    "    meta = loadmat(mat_path)\n",
    "    annots = meta['annotations']\n",
    "    c_name = annots[:, :][['class', 'fname']].squeeze(0)\n",
    "    c = list(map(lambda x: x.item(), c_name['class']))\n",
    "    name = list(map(lambda x: x.item(), c_name['fname']))\n",
    "    df = pd.DataFrame({\n",
    "        'class': c,\n",
    "        'fname': name\n",
    "    })\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_mat_to_csv('../data/cars_train_annos.mat', '../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = CarsDataset('../data/train', '../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8144,) (8144,)\n"
     ]
    }
   ],
   "source": [
    "it = iter(dts)\n",
    "hws = np.array((list(map(lambda x: x[0].size, it))))\n",
    "h, w = map(lambda x: x.squeeze(1), np.split(hws, 2, axis=1))\n",
    "print(h.shape, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(h)))\n",
    "print(len(np.unique(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(X, ft, fn, ac=True):\n",
    "    out = ft(X).detach().numpy()\n",
    "    outn = fn(X.detach().numpy())\n",
    "    print('MSE', np.power(out - outn, 2).sum())\n",
    "    if ac:\n",
    "        print('eq', np.allclose(out, outn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b0(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = Linear(512, 128)\n",
    "ln = LinearLayer(512, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.W = lt.weight.data.numpy()\n",
    "ln.b = lt.bias.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1, 512))\n",
    "Xn = X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5755734e-13\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "out = lt(X).detach().numpy()\n",
    "outn = ln(Xn)\n",
    "print(np.power(out - outn, 2).sum())\n",
    "print(np.allclose(out, outn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = Conv2d(3, 4, 3)\n",
    "cn = ConvLayer(3, 4, 3)\n",
    "wt, bt = ct._parameters.values()\n",
    "# cn.W = np.transpose(wt.data.numpy(), (0, 1, 2, 3))\n",
    "cn.W = wt.data.numpy()\n",
    "cn.b = bt.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(4, 3, 5, 5)\n",
    "Xn = X.numpy()\n",
    "# Xn = np.arange(48).reshape(1, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 3, 3) (4, 4, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "out = ct(X).detach().numpy()\n",
    "outn = cn(Xn)\n",
    "print(*(x.shape for x in (out, outn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0724481e-13\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.power(out - outn, 2).sum())\n",
    "# print(np.power(out - outn2, 2).sum())\n",
    "# print(np.power(out - outn3, 2).sum())\n",
    "# print(np.power(out - outn4, 2).sum())\n",
    "print(np.allclose(out, outn))\n",
    "# print(np.allclose(out, outn2))\n",
    "# print(np.allclose(out, outn3))\n",
    "# print(np.allclose(out, outn4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1.339315e-13\n",
      "eq True\n",
      "MSE 1.314504e-13\n",
      "eq True\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(5, 3, 4, 4)\n",
    "compare(X, SiLU(), SiLULayer())\n",
    "compare(X, Sigmoid(), SigmoidLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(5, 3, 16, 16)\n",
    "avgpool = AdaptiveAvgPool2d(output_size=1)\n",
    "out = avgpool(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Md(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(8, 4)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.l1(X)\n",
    "        x = self.act1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md = Md()\n",
    "md = nn.Linear(8, 4)\n",
    "mdn = LinearLayer(8, 4)\n",
    "mdn.W = md.weight.data.numpy()\n",
    "mdn.b = md.bias.data.numpy()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(5, 8)\n",
    "lab = torch.randint(0, 4, (5,))\n",
    "Xn = X.numpy()\n",
    "labn = lab.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3982, grad_fn=<NllLossBackward0>)\n",
      "1.3982131\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "out = md(X)\n",
    "outn = mdn(Xn)\n",
    "loss = crit(out, lab)\n",
    "lossn = critn(outn, labn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()\n",
    "sm = SoftmaxLayer()\n",
    "cre = CrossEntropyCost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = torch.rand(10, 4, requires_grad=True)\n",
    "lab0 = torch.randint(0, 4, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "# X = torch.rand(bs, 4, requires_grad=True)\n",
    "# lab = torch.randint(0, 4, (bs,))\n",
    "X = X0[:bs, :].clone().detach().requires_grad_(True)\n",
    "lab = lab0[:bs].clone().detach()\n",
    "Xn = X.detach().numpy()\n",
    "labn = lab.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "out1 = crit(X, lab)\n",
    "out2 = critn(Xn, labn)\n",
    "_out3 = sm(Xn)\n",
    "out3 = cre(_out3, labn)\n",
    "print(np.allclose(out1.detach(), out3))\n",
    "print(np.allclose(out1.detach(), out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward is right True\n"
     ]
    }
   ],
   "source": [
    "rest, resn, xts, xns, gt, gn = check_comb([crit], [sm, cre], X0, lab0, return_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = nn.Linear(676, 4)\n",
    "mdn = LinearLayer(676, 4)\n",
    "mdn.W = md.weight.data.numpy()\n",
    "mdn.b = md.bias.data.numpy()\n",
    "sil = SiLU()\n",
    "siln = SiLULayer()\n",
    "sig = Sigmoid()\n",
    "sign = SigmoidLayer()\n",
    "crit = nn.CrossEntropyLoss(reduction='mean')\n",
    "critn = CrossEntropyLoss()\n",
    "c = Conv2d(3, 4, 3)\n",
    "cn = ConvLayer(3, 4, 3)\n",
    "cn.W = c.weight.data.numpy()\n",
    "cn.b = c.bias.data.numpy()\n",
    "dc = Conv2d(2, 2, 3, stride=(2,2), groups=2, bias=False)\n",
    "dcn = DepthwiseConvLayer(2, 3, stride=2)\n",
    "dcn.W = ttn(dc.weight.data)\n",
    "f = Flatten()\n",
    "fn = FlattenLayer()\n",
    "trash = OneLayer()\n",
    "d = Dropout()\n",
    "dn = DropoutLayer()\n",
    "b = BatchNorm2d(4, track_running_stats=False)\n",
    "bn = BatchNorm2dLayer(4)\n",
    "bn.W = ttn(b.weight.data)\n",
    "bn.b = ttn(b.bias.data)\n",
    "a = AvgPool2d(2)\n",
    "ad = AdaptiveAvgPool2d(6)\n",
    "an = AvgPool2dLayer(2)\n",
    "adn = AdaptiveAvgPool2dLayer(6)\n",
    "seq = Sequential(c, b, f, md)\n",
    "seqn = SequentialLayer(cn, bn, fn, mdn)\n",
    "seq1 = SequentialLayer(seqn, seqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "X0 = torch.rand(bs, 3, 15, 15, requires_grad=True)\n",
    "# X0 = torch.rand(bs, 4, requires_grad=True)\n",
    "lab0 = torch.randint(0, 4, (bs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward is right True\n",
      "but 1.4210854715202004e-14\n"
     ]
    }
   ],
   "source": [
    "# [cn, bn, fn, mdn, critn]\n",
    "# [dcn, fn, mdn, critn]\n",
    "try:\n",
    "    res = check_comb([seq, crit], [seqn, critn], X0, lab0, return_grad=True)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "rest, resn, xts, xns, gt, gn = res\n",
    "print(len(gt), len(gn))\n",
    "print(len(xts), len(xns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 5\n",
    "print('\\n'.join(map(lambda x: str(np.allclose(x[0], x[1])), zip(gt, gn, list(range(grad_idx))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 6\n",
    "print('\\n'.join(map(lambda x: str(np.allclose(ttn(x[0]), x[1])), zip(xts, xns, list(range(grad_idx))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X deltas:\n",
      "0.0\n",
      "5.163924681822105e-16\n",
      "1.4210854715202004e-14\n",
      "------------------------------\n",
      "dX deltas:\n",
      "1.1397676087886308e-19\n",
      "6.24932017377787e-22\n",
      "------------------------------\n",
      "dXn mean\n",
      "1.8626452e-10\n",
      "-4.4151588e-12\n",
      "------------------------------\n",
      "dXt mean\n",
      "8.381903e-10\n",
      "-3.090611e-11\n"
     ]
    }
   ],
   "source": [
    "grad_idx = 6\n",
    "print('X deltas:')\n",
    "print('\\n'.join(map(lambda x: str(np.mean(ttn(x[0]) - x[1])**2), zip(xts, xns, list(range(grad_idx))))))\n",
    "print('-'*30)\n",
    "print('dX deltas:')\n",
    "print('\\n'.join(map(lambda x: str(np.mean(ttn(x[0]) - x[1])**2), zip(gt, gn, list(range(grad_idx-1))))))\n",
    "print('-'*30)\n",
    "print('dXn mean')\n",
    "print('\\n'.join(map(str, map(np.mean, gn))))\n",
    "print('-'*30)\n",
    "print('dXt mean')\n",
    "print('\\n'.join(map(str, map(np.mean, map(ttn, gt)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 15, 15) (10, 4) ()\n",
      "(10, 3, 15, 15) (10, 4) ()\n",
      "(10, 4) (10, 3, 15, 15)\n",
      "(10, 4) (10, 3, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "print(*map(lambda x: tuple(x.shape), xts))\n",
    "print(*map(lambda x: x.shape, xns))\n",
    "print(*map(lambda x: tuple(x.shape), gt))\n",
    "print(*map(lambda x: x.shape, gn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "se = SqueezeExcitationLayer(32, 8)\n",
    "X = np.random.rand(1, 32, 8, 8)\n",
    "r = se(X)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = EfficientNet([\n",
    "    MBconfig(*args)\n",
    "    for args in [\n",
    "        (1, 3, 1, 32, 16, 1),\n",
    "        (6, 3, 2, 16, 24, 2),\n",
    "        (6, 5, 2, 24, 40, 2),\n",
    "        (6, 3, 2, 40, 80, 3),\n",
    "        (6, 5, 1, 80, 112, 3),\n",
    "        (6, 5, 2, 112, 192, 4),\n",
    "        (6, 3, 1, 192, 320, 1),\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (96) must match the size of tensor b (98) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m8\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m600\u001b[39m, \u001b[39m400\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m y \u001b[39m=\u001b[39m en(X)\n",
      "File \u001b[0;32m~/python_envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/Itmo/DLProgramming/DeepLearningProgramming/lab01/src/torch_utils/models.py:33\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 33\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(x)\n\u001b[1;32m     35\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m     36\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/python_envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python_envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/python_envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python_envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/python_envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/Itmo/DLProgramming/DeepLearningProgramming/lab01/src/torch_utils/layers.py:207\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res:\n\u001b[1;32m    206\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n\u001b[0;32m--> 207\u001b[0m     result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (96) must match the size of tensor b (98) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "X = torch.rand((8, 3, 600, 400))\n",
    "y = en(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63de50e7b25e2d4530c1fba2f289d719b4cf6796b377066a37d3e20c0a10034f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
